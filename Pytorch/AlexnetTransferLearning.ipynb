{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c724c8e1ee6ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "prefix=os.path.abspath(os.path.dirname(os.getcwd()))+\"/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc39be6db006645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "breed = prefix+\"data/breed.csv\"\n",
    "filename = prefix+\"data/labels.csv\"\n",
    "labelsNames = [\"id\", \"breed\"]\n",
    "labels = read_csv(filename, names=labelsNames)\n",
    "\n",
    "breedNames = read_csv(breed)[\"breed\"].tolist()[1:]\n",
    "print(labels.shape)\n",
    "# print(len(breedNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eebc2cac669321",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(list(set(labels[\"breed\"].tolist()[1:])))\n",
    "data_label = le.transform(labels[\"breed\"].tolist()[1:])\n",
    "print(len(data_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe8ece25cd3d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(256),\n",
    "            transforms.RandomCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),  # Apply random horizontal flip\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]  # Normalize tensor image with mean and std\n",
    "            ),  # input = (input - mean) / std\n",
    "        ]\n",
    "    ),\n",
    "    \"val\": transforms.Compose(\n",
    "        [\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),  # For validation, only center crop is needed\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]  # Normalize tensor image with mean\n",
    "            ),  # and std\n",
    "        ]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32918a6ac2ade7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels_files = labels[\"id\"].apply(lambda x: prefix+\"/data/train/\" + x + \".jpg\").tolist()[1:]\n",
    "train_path, val_path, train_label, val_label = train_test_split(\n",
    "    labels_files, data_label, test_size=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17916c2452a6183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from skimage import io  # Assuming you are using skimage to read images\n",
    "\n",
    "class DogDataset(Dataset):\n",
    "    def __init__(self, data_path, data_label, transform=None):\n",
    "        \"\"\"\n",
    "        - data_path (string): Path to the images\n",
    "        - data_label (string): Labels for the images\n",
    "        - transform (callable, optional): A function/transform to apply to each sample\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.data_label = data_label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data_path[idx]\n",
    "        image = io.imread(img_path)\n",
    "        label = self.data_label[idx]\n",
    "\n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155c39599fd1ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DogDataset(train_path, train_label, data_transforms[\"train\"])\n",
    "val_dataset = DogDataset(val_path, val_label, data_transforms[\"val\"])\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1475a88b63450517",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for batch_index, sample_batch in enumerate(train_loader):\n",
    "    images, labels = sample_batch\n",
    "    sample_images = make_grid(images, normalize=True)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(sample_images.permute(1, 2, 0).numpy())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5645927283b6987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3b7baeb822741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in alexnet.parameters():\n",
    "    param.requires_grad = False\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fc783d25575a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = list(alexnet.classifier.children())  # Get all layers of the classifier\n",
    "# Replace the last layer from Linear(4096, 1000) to Linear(4096, 120)\n",
    "classifier[-1] = torch.nn.Linear(4096, 120)\n",
    "classifier.append(torch.nn.Softmax(dim=1))  # Add a Softmax layer\n",
    "alexnet.classifier = torch.nn.Sequential(*classifier)  # Update the original classifier\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a8cec1373f28f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb08e7ff07435692",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()  # Cross-entropy loss function\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, alexnet.parameters()), lr=0.001\n",
    ")  # Optimizer\n",
    "# Learning rate decay: after every 1 iteration, decay learning rate by a factor of 0.5\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "\n",
    "criterion, optimizer, lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "id": "34fd3579a3050dc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T14:07:44.097959Z",
     "start_time": "2024-09-05T14:07:43.964657Z"
    }
   },
   "source": [
    "epochs = 100\n",
    "model = alexnet.to(dev)\n",
    "print(\"Start Training...\")\n",
    "if os.path.exists(prefix + \"models/model.pt\"):  # Check if a pre-trained model exists\n",
    "    model_saved = alexnet\n",
    "    model_saved.load_state_dict(torch.load(prefix+\"models/model.pt\", weights_only=True))\n",
    "    model = model_saved.to(dev)\n",
    "    print(\"Load model from model.pt\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(dev)  # Move images to the device (GPU or CPU)\n",
    "        labels = labels.to(dev)  # Move labels to the device (GPU or CPU)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels.type(torch.int64))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                \"Epoch [{}/{}], Batch [{}/{}], Train loss: {:.3f}\".format(\n",
    "                    epoch + 1, epochs, i + 1, len(train_loader), loss.item()\n",
    "                )\n",
    "            )\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Save model to model.pt\")\n",
    "        torch.save(model.state_dict(), prefix + \"models/model.pt\")\n",
    "\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(dev)  # Move images to the device (GPU or CPU)\n",
    "        labels = labels.to(dev)  # Move labels to the device (GPU or CPU)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(\"============ Test accuracy: {:.3f} =============\".format(correct / total))\n",
    "\n",
    "    lr_scheduler.step()  # Apply learning rate decay"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alexnet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_33960\\2699040026.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mepochs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m100\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0malexnet\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdev\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Start Training...\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexists\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprefix\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34m\"models/model.pt\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# Check if a pre-trained model exists\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mmodel_saved\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0malexnet\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'alexnet' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a4e24fe2b5f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), prefix+\"models/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8abc032756ce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE = io.imread(\"data/train/0AjbbdBwNiGqWo5n.jpg\")\n",
    "IMAGE = data_transforms[\"val\"](IMAGE).unsqueeze(0)  \n",
    "IMAGE.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641b4e607173139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= model_saved(IMAGE.to(dev))\n",
    "# probality = model_saved(IMAGE.to(dev))\n",
    "# print(probality)\n",
    "# print(le.inverse_transform([data]))\n",
    "tempDict = {}\n",
    "for i in range(len(data[0])):\n",
    "    tempDict[le.inverse_transform([i])[0]] = data[0][i].item()\n",
    "temp=pd.DataFrame(tempDict,index=[0])\n",
    "temp.insert(0,\"id\",\"0AjbbdBwNiGqWo5n\")\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5018affb2f9982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a48e21f2693e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdata= pd.DataFrame(columns=[\"id\"]+breedNames)\n",
    "outdata\n",
    "testPath = os.getcwd()+\"/data/test/\"\n",
    "files= os.listdir(testPath)\n",
    "\n",
    "p=0\n",
    "\n",
    "for file in tqdm(files):\n",
    "    p+=1\n",
    "    IMAGE = io.imread(testPath+file)\n",
    "    IMAGE = data_transforms[\"val\"](IMAGE).unsqueeze(0)\n",
    "    data= model_saved(IMAGE.to(dev))\n",
    "    tempDict = {}\n",
    "    for i in range(len(data[0])):\n",
    "        tempDict[le.inverse_transform([i])[0]] = data[0][i].item()\n",
    "    temp=pd.DataFrame(tempDict,index=[0])\n",
    "    temp.insert(0,\"id\",file[:-4])\n",
    "    outdata=pd.concat([outdata,temp],ignore_index=True)\n",
    "outdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6a4431d70a61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"output.csv\" \n",
    "columns_sorted = [\"id\"] + sorted(col for col in outdata.columns if col != \"id\")\n",
    "outdata = outdata[columns_sorted]\n",
    "outdata.to_csv(output_path, index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd2bffef4aa380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
